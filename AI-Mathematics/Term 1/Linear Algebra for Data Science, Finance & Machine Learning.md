# **Course Title:** Linear Algebra for Data Science, Finance & Machine Learning

---

### **Chapter 1: Vector Spaces & Subspaces**

* [ ] Vector spaces: definitions, examples (ℝⁿ, polynomial spaces, function spaces)
* [ ] Subspaces, span, linear independence, dimension
* [ ] Basis and change of basis
* [ ] Row space, column space, null space
* [ ] Orthogonality and orthogonal projections
* [ ] **Industry case:** Portfolio weights & asset space as vectors

---

### **Chapter 2: Linear Transformations & Matrix Representation**

* [ ] Definition of linear transformation
* [ ] Matrix representation of linear maps
* [ ] Rank and nullity, rank-nullity theorem
* [ ] Properties of linear transformations (invertibility, composition)
* [ ] Symmetric, skew-symmetric, orthogonal matrices
* [ ] **Industry case:** Transition matrices in Markov Chains (credit rating models)

---

### **Chapter 3: Eigenvalues, Eigenvectors & Diagonalization**

* [ ] Eigenvalues and eigenvectors (definition, computation)
* [ ] Diagonalization and its conditions
* [ ] Applications of eigenvalues (stability, variance explanation in PCA)
* [ ] Spectral theorem for symmetric matrices
* [ ] **Industry case:** PCA for dimensionality reduction in quant/finance datasets

---

### **Chapter 4: Quadratic Forms & Canonical Representations**

* [ ] Definition and examples of quadratic forms
* [ ] Positive definite, semi-definite, and indefinite forms
* [ ] Matrix representation of quadratic forms
* [ ] Hermite canonical form
* [ ] Generalized inverses (Moore-Penrose pseudo-inverse)
* [ ] **Industry case:** Optimization problems (mean-variance portfolio optimization)

---

### **Chapter 5: Singular Value Decomposition (SVD) & Applications**

* [ ] Singular values and singular vectors
* [ ] Derivation and properties of SVD
* [ ] Low-rank approximations and compression
* [ ] Connection between SVD and PCA
* [ ] **Industry case:**

  * Risk factor modeling in finance (principal components)
  * Latent factors in recommendation systems
  * Noise reduction in time series & image data

---

### **Chapter 6: Matrix Calculus & Advanced Applications**

* [ ] Matrix differentiation (gradients & Hessians with matrices)
* [ ] Kronecker products and block matrices
* [ ] Orthogonalization methods (Gram-Schmidt, QR decomposition)
* [ ] Applications in optimization & machine learning
* [ ] **Capstone Project:**

  * [ ] Implement PCA using eigen decomposition & SVD on a financial dataset
  * [ ] Apply quadratic forms in portfolio optimization
  * [ ] Use regression with matrix algebra (normal equations, least squares)

---
